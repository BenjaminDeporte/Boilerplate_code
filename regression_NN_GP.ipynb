{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7dc0ede",
   "metadata": {},
   "source": [
    "# Comparing regression analysis with:\n",
    "- a neural network\n",
    "- a gaussian process regressor\n",
    "\n",
    "We want to predict the inherent playing value of a rugby player, based on his skills !\n",
    "The overall value is measured by CSR (Compound Skills Rating).\n",
    "The skills are physical and technical attributes.\n",
    "\n",
    "We aim at comparing two algorithms : a sequential neural network, and a Gaussian Process regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb453a3",
   "metadata": {},
   "source": [
    "### Import librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2838cb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import gpytorch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import timeit\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f935c925",
   "metadata": {},
   "source": [
    "### NB : works better and faster with a GPU..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef64263d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    dtype = torch.FloatTensor\n",
    "\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print('GPU Name:', torch.cuda.get_device_name(0))\n",
    "    print('Total GPU Memory:', round(torch.cuda.get_device_properties(0).total_memory/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbeccd9",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca02cec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './data/df_tm.csv'\n",
    "data = pd.read_csv(filename, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62c3b060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>stamina</th>\n",
       "      <th>handling</th>\n",
       "      <th>attack</th>\n",
       "      <th>defense</th>\n",
       "      <th>technique</th>\n",
       "      <th>strength</th>\n",
       "      <th>jumping</th>\n",
       "      <th>speed</th>\n",
       "      <th>agility</th>\n",
       "      <th>kicking</th>\n",
       "      <th>form</th>\n",
       "      <th>aggression</th>\n",
       "      <th>discipline</th>\n",
       "      <th>leadership</th>\n",
       "      <th>experience</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>csr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>141146.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>103797.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>86828.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>225912.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>36298.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34192</th>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>226718.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34193</th>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>198687.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34194</th>\n",
       "      <td>26.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>194528.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34195</th>\n",
       "      <td>27.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>194577.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34196</th>\n",
       "      <td>25.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>142968.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34197 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  stamina  handling  attack  defense  technique  strength  jumping  \\\n",
       "0      34.0     14.0      13.0    12.0     14.0       15.0      14.0     13.0   \n",
       "1      33.0     13.0      12.0    14.0     16.0        6.0       6.0      7.0   \n",
       "2      25.0     12.0      11.0    15.0     15.0       13.0      11.0      8.0   \n",
       "3      33.0     17.0      17.0    15.0     14.0       17.0      17.0     11.0   \n",
       "4      17.0     10.0      11.0     7.0      5.0       10.0       9.0     12.0   \n",
       "...     ...      ...       ...     ...      ...        ...       ...      ...   \n",
       "34192  30.0     14.0      18.0    16.0     13.0       18.0      18.0      9.0   \n",
       "34193  30.0     14.0      15.0    16.0     14.0       18.0      17.0      8.0   \n",
       "34194  26.0     15.0      17.0    14.0     13.0       17.0      16.0      9.0   \n",
       "34195  27.0     16.0      14.0    14.0     14.0       17.0      18.0      8.0   \n",
       "34196  25.0     13.0      13.0    11.0     13.0       16.0      16.0     10.0   \n",
       "\n",
       "       speed  agility  kicking  form  aggression  discipline  leadership  \\\n",
       "0       11.0     12.0      1.0   9.0         3.0         4.0         5.0   \n",
       "1       13.0     11.0     12.0   8.0         2.0         3.0         8.0   \n",
       "2        7.0      6.0      3.0   6.0         3.0         4.0         4.0   \n",
       "3       13.0      8.0      3.0   8.0         2.0         3.0         3.0   \n",
       "4        8.0      5.0      3.0   8.0         2.0         4.0         8.0   \n",
       "...      ...      ...      ...   ...         ...         ...         ...   \n",
       "34192    9.0     12.0     10.0   9.0         3.0         2.0         6.0   \n",
       "34193   12.0     11.0      8.0   7.0         3.0         5.0         9.0   \n",
       "34194   14.0     12.0      8.0   6.0         3.0         3.0         7.0   \n",
       "34195   12.0     11.0      8.0   9.0         2.0         4.0         9.0   \n",
       "34196   11.0     12.0      7.0   9.0         3.0         2.0         2.0   \n",
       "\n",
       "       experience  weight  height       csr  \n",
       "0             8.0   112.0   203.0  141146.0  \n",
       "1             7.0    83.0   191.0  103797.0  \n",
       "2             3.0    99.0   188.0   86828.0  \n",
       "3             7.0   120.0   197.0  225912.0  \n",
       "4             1.0   111.0   200.0   36298.0  \n",
       "...           ...     ...     ...       ...  \n",
       "34192         7.0   117.0   182.0  226718.0  \n",
       "34193         3.0   101.0   189.0  198687.0  \n",
       "34194         5.0    95.0   195.0  194528.0  \n",
       "34195         4.0   118.0   186.0  194577.0  \n",
       "34196         4.0   113.0   182.0  142968.0  \n",
       "\n",
       "[34197 rows x 19 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(columns=['energy'], inplace=True)  # Remove the 'energy' column as it is not needed for regression analysis\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7572300c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>34197.0</td>\n",
       "      <td>24.897476</td>\n",
       "      <td>6.675492</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stamina</th>\n",
       "      <td>34197.0</td>\n",
       "      <td>13.442203</td>\n",
       "      <td>3.676856</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>handling</th>\n",
       "      <td>34197.0</td>\n",
       "      <td>12.901102</td>\n",
       "      <td>3.547711</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attack</th>\n",
       "      <td>34197.0</td>\n",
       "      <td>12.844489</td>\n",
       "      <td>3.506895</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>defense</th>\n",
       "      <td>34197.0</td>\n",
       "      <td>13.434950</td>\n",
       "      <td>3.323040</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technique</th>\n",
       "      <td>34197.0</td>\n",
       "      <td>11.710296</td>\n",
       "      <td>3.975157</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strength</th>\n",
       "      <td>34197.0</td>\n",
       "      <td>11.661140</td>\n",
       "      <td>3.979813</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jumping</th>\n",
       "      <td>34197.0</td>\n",
       "      <td>7.262450</td>\n",
       "      <td>3.790435</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speed</th>\n",
       "      <td>34197.0</td>\n",
       "      <td>11.537269</td>\n",
       "      <td>3.924281</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agility</th>\n",
       "      <td>34197.0</td>\n",
       "      <td>9.775887</td>\n",
       "      <td>4.051186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kicking</th>\n",
       "      <td>34197.0</td>\n",
       "      <td>5.469690</td>\n",
       "      <td>4.089127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>form</th>\n",
       "      <td>34197.0</td>\n",
       "      <td>7.427201</td>\n",
       "      <td>1.426792</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aggression</th>\n",
       "      <td>34197.0</td>\n",
       "      <td>3.005790</td>\n",
       "      <td>1.058568</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discipline</th>\n",
       "      <td>34197.0</td>\n",
       "      <td>3.026143</td>\n",
       "      <td>1.052692</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leadership</th>\n",
       "      <td>34197.0</td>\n",
       "      <td>6.002369</td>\n",
       "      <td>2.277885</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experience</th>\n",
       "      <td>34197.0</td>\n",
       "      <td>4.145451</td>\n",
       "      <td>2.468485</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>34197.0</td>\n",
       "      <td>102.039506</td>\n",
       "      <td>14.583288</td>\n",
       "      <td>65.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>height</th>\n",
       "      <td>34197.0</td>\n",
       "      <td>187.527356</td>\n",
       "      <td>7.700875</td>\n",
       "      <td>167.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>csr</th>\n",
       "      <td>34197.0</td>\n",
       "      <td>138340.264614</td>\n",
       "      <td>96033.341158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77791.0</td>\n",
       "      <td>101158.0</td>\n",
       "      <td>195864.0</td>\n",
       "      <td>779659.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count           mean           std    min      25%       50%  \\\n",
       "age         34197.0      24.897476      6.675492   17.0     20.0      21.0   \n",
       "stamina     34197.0      13.442203      3.676856    1.0     12.0      14.0   \n",
       "handling    34197.0      12.901102      3.547711    1.0     11.0      14.0   \n",
       "attack      34197.0      12.844489      3.506895    1.0     11.0      14.0   \n",
       "defense     34197.0      13.434950      3.323040    1.0     12.0      14.0   \n",
       "technique   34197.0      11.710296      3.975157    1.0      9.0      12.0   \n",
       "strength    34197.0      11.661140      3.979813    1.0      9.0      12.0   \n",
       "jumping     34197.0       7.262450      3.790435    1.0      5.0       7.0   \n",
       "speed       34197.0      11.537269      3.924281    1.0      9.0      12.0   \n",
       "agility     34197.0       9.775887      4.051186    1.0      7.0      10.0   \n",
       "kicking     34197.0       5.469690      4.089127    1.0      2.0       4.0   \n",
       "form        34197.0       7.427201      1.426792    1.0      6.0       7.0   \n",
       "aggression  34197.0       3.005790      1.058568    1.0      2.0       3.0   \n",
       "discipline  34197.0       3.026143      1.052692    1.0      2.0       3.0   \n",
       "leadership  34197.0       6.002369      2.277885    1.0      4.0       6.0   \n",
       "experience  34197.0       4.145451      2.468485    1.0      2.0       3.0   \n",
       "weight      34197.0     102.039506     14.583288   65.0     90.0     102.0   \n",
       "height      34197.0     187.527356      7.700875  167.0    182.0     187.0   \n",
       "csr         34197.0  138340.264614  96033.341158    0.0  77791.0  101158.0   \n",
       "\n",
       "                 75%       max  \n",
       "age             31.0      83.0  \n",
       "stamina         16.0      21.0  \n",
       "handling        15.0      21.0  \n",
       "attack          15.0      21.0  \n",
       "defense         16.0      21.0  \n",
       "technique       14.0      21.0  \n",
       "strength        14.0      21.0  \n",
       "jumping         10.0      21.0  \n",
       "speed           14.0      21.0  \n",
       "agility         13.0      21.0  \n",
       "kicking          8.0      21.0  \n",
       "form             8.0      11.0  \n",
       "aggression       4.0       5.0  \n",
       "discipline       4.0       5.0  \n",
       "leadership       8.0      11.0  \n",
       "experience       6.0      11.0  \n",
       "weight         114.0     145.0  \n",
       "height         193.0     215.0  \n",
       "csr         195864.0  779659.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eca370c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate features and target variable\n",
    "# 'csr' is the target variable we want to predict\n",
    "\n",
    "X = data.drop(columns=['csr'])\n",
    "y = data['csr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1074b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# form training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c9c5fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data for better performance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34ad7d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# form datasets and dataloaders for PyTorch training\n",
    "class CSRDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y.values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "train_dataset = CSRDataset(X_train_scaled, y_train)\n",
    "test_dataset = CSRDataset(X_test_scaled, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1554ce3d",
   "metadata": {},
   "source": [
    "## Regression by Multi Layer Perceptron network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3923a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form a simple multilayer perceptron model\n",
    "class CSRNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=128):\n",
    "        super(CSRNeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ### x has shape (batch_size, input_size)\n",
    "        x = self.relu(self.fc1(x))  # First layer with ReLU activation\n",
    "        x = self.relu(self.fc2(x))  # Second layer with ReLU activation\n",
    "        x = self.fc3(x)              # Output layer (no activation)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b05bfc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping class to prevent overfitting\n",
    "\n",
    "class EarlyStoppingCallback:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        # how many epochs do we accept with validation loss non decreasing\n",
    "        self.patience = patience\n",
    "        # tolerance for non decrease\n",
    "        self.min_delta = min_delta\n",
    "        # how many epochs without validation loss decrease\n",
    "        self.counter = 0\n",
    "        # minimum validation loss to beat\n",
    "        self.min_validation_loss = float('inf')\n",
    "        self.status = False\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        # is the last validation loss better than the current minimum ?\n",
    "        # status = True means stop training\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            # yes : update minimum value and reset counter\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "            self.status = False\n",
    "            # no : are we within tolerance ?\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            # no : increase counter (losing patience)\n",
    "            self.counter += 1\n",
    "            # have we lost patience ?\n",
    "            if self.counter >= self.patience:\n",
    "                # yes\n",
    "                self.status = True\n",
    "            else:\n",
    "                # no\n",
    "                self.status = False\n",
    "\n",
    "        return self.status, self.counter\n",
    "    \n",
    "early_stopping = EarlyStoppingCallback(patience=5, min_delta=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "064206fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss for regression\n",
    "\n",
    "model = CSRNeuralNetwork(input_size=X_train_scaled.shape[1])\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbef8607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Training Step\n",
    "def train_step(model, train_loader, learning_rate, criterion, optimizer):\n",
    "    \"\"\"Perform one training step on the model.\"\"\"\n",
    "    \n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = model(X_batch)  # Forward pass\n",
    "        loss = criterion(outputs.squeeze(), y_batch)\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return model, epoch_loss/len(train_loader)\n",
    "\n",
    "# One Test Step\n",
    "def test_step(model, test_loader, criterion):\n",
    "    \"\"\"Perform one test step on the model.\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            outputs = model(X_batch)  # Forward pass\n",
    "            loss = criterion(outputs.squeeze(), y_batch)\n",
    "            test_loss += loss.item()\n",
    "    \n",
    "    return test_loss / len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81e83930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "\n",
    "def train_model(model, train_loader, test_loader, n_epochs, learning_rate, criterion, optimizer, early_stopping=None):\n",
    "    \"\"\"Train the model with early stopping.\"\"\"\n",
    "    training_losses = []\n",
    "    validation_losses = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        # Train step\n",
    "        model, train_loss = train_step(model, train_loader, learning_rate, criterion, optimizer)\n",
    "        training_losses.append(train_loss)\n",
    "\n",
    "        # Test step\n",
    "        validation_loss = test_step(model, test_loader, criterion)\n",
    "        validation_losses.append(validation_loss)\n",
    "\n",
    "        print(f'Epoch [{epoch+1:<6} .../... {n_epochs:<6}], Training Loss: {train_loss:.4e}, Validation Loss: {validation_loss:.4e}')\n",
    "\n",
    "        # Early stopping check\n",
    "        if early_stopping:\n",
    "            stop, counter = early_stopping.early_stop(validation_loss)\n",
    "            if stop:\n",
    "                print(f'Early stopping at epoch {epoch+1} with counter {counter}')\n",
    "                break\n",
    "\n",
    "    return model, training_losses, validation_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091a52a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1      .../... 500   ], Training Loss: 1.8564e+10, Validation Loss: 4.3324e+09\n",
      "Epoch [2      .../... 500   ], Training Loss: 2.9654e+09, Validation Loss: 2.0198e+09\n",
      "Epoch [3      .../... 500   ], Training Loss: 1.2016e+09, Validation Loss: 6.7853e+08\n",
      "Epoch [4      .../... 500   ], Training Loss: 5.2877e+08, Validation Loss: 4.5691e+08\n",
      "Epoch [5      .../... 500   ], Training Loss: 4.2108e+08, Validation Loss: 4.0038e+08\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m n_epochs = \u001b[32m500\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m trained_model, training_losses, validation_losses = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, test_loader, n_epochs, learning_rate, criterion, optimizer, early_stopping)\u001b[39m\n\u001b[32m      6\u001b[39m validation_losses = []\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# Train step\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     model, train_loss = \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     training_losses.append(train_loss)\n\u001b[32m     13\u001b[39m     \u001b[38;5;66;03m# Test step\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mtrain_step\u001b[39m\u001b[34m(model, train_loader, learning_rate, criterion, optimizer)\u001b[39m\n\u001b[32m     10\u001b[39m     loss = criterion(outputs.squeeze(), y_batch)\n\u001b[32m     11\u001b[39m     loss.backward()  \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Update weights\u001b[39;00m\n\u001b[32m     13\u001b[39m     epoch_loss += loss.item()\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model, epoch_loss/\u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/torchy/lib/python3.13/site-packages/torch/optim/optimizer.py:516\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    511\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    512\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    513\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    514\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    519\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/torchy/lib/python3.13/site-packages/torch/optim/optimizer.py:81\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     79\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     80\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     83\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/torchy/lib/python3.13/site-packages/torch/optim/adam.py:247\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    235\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    237\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    238\u001b[39m         group,\n\u001b[32m    239\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    244\u001b[39m         state_steps,\n\u001b[32m    245\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/torchy/lib/python3.13/site-packages/torch/optim/optimizer.py:149\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/torchy/lib/python3.13/site-packages/torch/optim/adam.py:949\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    946\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    947\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m949\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/torchy/lib/python3.13/site-packages/torch/optim/adam.py:533\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    531\u001b[39m         denom = (max_exp_avg_sqs[i].sqrt() / bias_correction2_sqrt).add_(eps)\n\u001b[32m    532\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m533\u001b[39m         denom = \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m     param.addcdiv_(exp_avg, denom, value=-step_size)\n\u001b[32m    537\u001b[39m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "\n",
    "trained_model, training_losses, validation_losses = train_model(\n",
    "    model, train_loader, test_loader, n_epochs, learning_rate, criterion, optimizer, early_stopping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792d1956",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(training_losses, label='Training Loss', color='blue')\n",
    "ax.plot(validation_losses, label='Validation Loss', color='orange')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss (log scale)')\n",
    "ax.set_yscale('log')  # Use logarithmic scale for better visibility\n",
    "ax.set_title('Training and Validation Losses')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b04d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run metrics on the prediction by the trained model\n",
    "\n",
    "def run_metrics(model, test_loader):\n",
    "    \"\"\"Run metrics on the predictions made by the model.\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            outputs = model(X_batch)\n",
    "            predictions.extend(outputs.squeeze().numpy())\n",
    "            targets.extend(y_batch.numpy())\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    targets = np.array(targets)\n",
    "    \n",
    "    mse = np.mean((predictions - targets) ** 2)\n",
    "    mae = np.mean(np.abs(predictions - targets))\n",
    "    \n",
    "    print(f'Root Mean Squared Error: {np.sqrt(mse):.0f}')\n",
    "    print(f'Mean Absolute Error: {mae:.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05d894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_metrics(trained_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b10b546",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = trained_model(torch.tensor(X_test_scaled, dtype=torch.float32)).detach().numpy()\n",
    "\n",
    "df_test = pd.DataFrame(\n",
    "    {\n",
    "        'reel' : list(y_test),\n",
    "        'model' : list(y_pred)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ec2190",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.sort_values(by=['reel'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26858449",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,6))\n",
    "\n",
    "ax.plot(df_test['reel'].to_numpy(), label='target')\n",
    "ax.plot(df_test['model'].to_numpy(), label='predicted')\n",
    "ax.grid(True)\n",
    "ax.set_ylabel('csr')\n",
    "ax.set_title('MLP : predictions on test set, sorted by target value')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefff664",
   "metadata": {},
   "source": [
    "## Gaussian Process Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1727ec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is X_train, y_train and X_test, y_test\n",
    "N = 20000  # limited by gpu capacity.\n",
    "\n",
    "X_train_t = torch.tensor(X_train[:N].values, dtype=torch.float32)\n",
    "X_test_t = torch.tensor(X_test[:N].values, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train[:N].values, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test[:N].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101611e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Process Regressor Model\n",
    "\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        \n",
    "        \"\"\"An __init__ method that takes the training data and a likelihood, \n",
    "        and constructs whatever objects are necessary for the model\"s forward method. \n",
    "        This will most commonly include things like a mean module and a kernel module.\n",
    "        \"\"\"\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        # constant mean as prior mean\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        # RBF kernel as prior covariance\n",
    "        # NB : in GPyTorch, the white noise is handled by the likelihood, not the kernel\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"A forward method that takes in some n x d data x and returns a MultivariateNormal with the prior mean and covariance evaluated at x. \n",
    "        In other words, we return the vector mu(x) and the n x n matrix representing the prior mean and covariance matrix of the GP.\n",
    "        \"\"\"\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f839042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize likelihood\n",
    "# The simplest likelihood for regression is the gpytorch.likelihoods.GaussianLikelihood. \n",
    "# This assumes a homoskedastic noise model (i.e. all inputs have the same observational noise).\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood(noise_prior=gpytorch.priors.NormalPrior(1e+4, 1e+5), learn_additional_noise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2448464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = ExactGPModel(X_train_t, y_train_t, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e19f2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model on GPU if available\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Going to GPU\")\n",
    "    model = model.cuda()\n",
    "    likelihood = likelihood.cuda()\n",
    "    X_train_t = X_train_t.cuda()\n",
    "    y_train_t = y_train_t.cuda()\n",
    "    X_test_t = X_test_t.cuda()\n",
    "    y_test_t = y_test_t.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f412a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n epochs\n",
    "training_iter = 0\n",
    "iter_max = 3000  # maximum number of iterations for training\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "# error threshold\n",
    "error_threshold = 1e-8\n",
    "previous_loss = np.inf\n",
    "error = np.inf\n",
    "\n",
    "# training loop\n",
    "t1 = timeit.default_timer()\n",
    "print(\"Training GP model with GP Torch...\")\n",
    "\n",
    "# while error > error_threshold and training_iter <= iter_max:\n",
    "while training_iter <= iter_max:\n",
    "# for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(X_train_t)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, y_train_t)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # check error\n",
    "    if training_iter >= 1:\n",
    "        error = np.abs(previous_loss - loss.item())/ previous_loss\n",
    "    previous_loss = loss.item()\n",
    "    # report out\n",
    "    if training_iter % 10 == 0:\n",
    "        print(f\"Iteration [{training_iter+1:<6} .../... {iter_max:<6}], Loss: {loss.item():.3e}, Error decrease on last iteration: {error*100:.2e}%, lengthscale : {model.covar_module.base_kernel.lengthscale.item():.2e}, noise (variance): {model.likelihood.noise.item():.2e}\")\n",
    "    # next iteration\n",
    "    training_iter += 1\n",
    "    \n",
    "t2 = timeit.default_timer()\n",
    "print(\"Training time: {:.2f} seconds\".format(t2 - t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390d1c50",
   "metadata": {},
   "source": [
    "Plot model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195e6705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get into evaluation (predictive posterior) mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Number of test points\n",
    "N = 200\n",
    "OFFSET = 200000\n",
    "\n",
    "# Make predictions by feeding model through likelihood\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    observed_pred = likelihood(model(X_test_t[:N]))  # returns a MultivariateNormal object, not a tensor !\n",
    "\n",
    "# Plotting the results\n",
    "with torch.no_grad():\n",
    "    # Initialize plot\n",
    "    f, ax = plt.subplots(2, 1, figsize=(20, 6))\n",
    "    \n",
    "    # plot ground truth\n",
    "    ax[0].plot(y_test_t[:N].cpu().numpy(), 'r', label='Ground Truth')\n",
    "    # plot observed values with credible interval\n",
    "    ax[0].plot(observed_pred.mean.cpu().numpy()+OFFSET, 'k', label='Predicted Values')\n",
    "    ax[0].fill_between(\n",
    "        np.arange(N),\n",
    "        observed_pred.mean.cpu().numpy() + OFFSET - 1.96 * observed_pred.stddev.cpu().numpy(),\n",
    "        observed_pred.mean.cpu().numpy() + OFFSET + 1.96 * observed_pred.stddev.cpu().numpy(),\n",
    "        alpha=0.5,\n",
    "        color='blue',\n",
    "        label='95% Confidence Interval'\n",
    "    )\n",
    "    # Set title and labels\n",
    "    ax[0].set_title('GP Regression with GPyTorch')\n",
    "    ax[0].set_xlabel('Test Data Index')\n",
    "    ax[0].set_ylabel('Output Value')\n",
    "\n",
    "    ax[0].legend()\n",
    "    ax[0].grid()\n",
    "    \n",
    "    # lot the residuals\n",
    "    residuals = observed_pred.mean.cpu().numpy() - y_test_t[:N].cpu().numpy()\n",
    "    ax[1].plot(residuals, 'b', label='Residuals')\n",
    "    ax[1].axhline(0, color='red', linestyle='--', label='Zero Line')\n",
    "    ax[1].set_title('Residuals of GP Regression')\n",
    "    ax[1].set_xlabel('Test Data Index')\n",
    "    ax[1].set_ylabel('Residual Value')\n",
    "    \n",
    "    ax[1].fill_between(\n",
    "        np.arange(N),\n",
    "        0 - 1.96 * observed_pred.stddev.cpu().numpy(),\n",
    "        0 + 1.96 * observed_pred.stddev.cpu().numpy(),\n",
    "        alpha=0.5,\n",
    "        color='blue',\n",
    "        label='95% Confidence Interval for Residuals'\n",
    "    )\n",
    "    \n",
    "    ax[1].legend()\n",
    "    ax[1].grid()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0c99a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metrics\n",
    "# Get into evaluation (predictive posterior) mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Make predictions by feeding model through likelihood\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    full_preds = likelihood(model(X_test_t))\n",
    "\n",
    "print(f'MAE = {mean_absolute_error(y_test_t.cpu(), full_preds.mean.cpu()):.0f}')\n",
    "print(f'RMSE = {np.sqrt(mean_squared_error(y_test_t.cpu(), full_preds.mean.cpu())):.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2e50f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(\n",
    "    {\n",
    "        'reel' : list(y_test),\n",
    "        'model' : list(full_preds.mean.cpu().numpy())  # use mean of the predictive distribution\n",
    "    }\n",
    ")\n",
    "df_test.sort_values(by=['reel'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01152342",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,6))\n",
    "\n",
    "ax.plot(df_test['reel'].to_numpy(), label='target')\n",
    "ax.plot(df_test['model'].to_numpy(), label='predicted')\n",
    "ax.grid(True)\n",
    "ax.set_ylabel('csr')\n",
    "ax.set_title('GPR : predictions on test set, sorted by target value')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09395824",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74355fe1",
   "metadata": {},
   "source": [
    "- The simple **Multi Layer Perceptron** is well suited to the regression task, and provides point estimates with good precisions (RMSE, MAE metrics). However, it does not provide credible intervals.\n",
    "- The **Gaussian Process regressor** takes longer to train, as it naively scales in $O(n^3)$, and seems to have a lower precision. However, it can provide credible intervals."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
