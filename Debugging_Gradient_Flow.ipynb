{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e595d4b7",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Debugging the Gradient Flow\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd34fa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"name : {name}, param = {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910a7bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_gradient_flow(model):\n",
    "    \"\"\"Check gradient flow for all parameters\"\"\"\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            if param.grad is not None:\n",
    "                grad_norm = param.grad.norm().item()\n",
    "                print(f\"{name}: grad_norm = {grad_norm:.6f}\")\n",
    "            else:\n",
    "                print(f\"{name}: NO GRADIENT\")\n",
    "        else:\n",
    "            print(f\"{name}: requires_grad = False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e5cfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install torchviz if not already installed\n",
    "# pip install torchviz\n",
    "\n",
    "try:\n",
    "    from torchviz import make_dot\n",
    "    TORCHVIZ_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"torchviz not available. Install with: pip install torchviz\")\n",
    "    TORCHVIZ_AVAILABLE = False\n",
    "\n",
    "def visualize_computational_graph(loss, model, save_path=\"computation_graph\"):\n",
    "    \"\"\"Visualize computational graph\"\"\"\n",
    "    if TORCHVIZ_AVAILABLE:\n",
    "        # Create computational graph\n",
    "        params = dict(model.named_parameters())\n",
    "        dot = make_dot(loss, params=params)\n",
    "        \n",
    "        # Save and display\n",
    "        dot.format = 'png'\n",
    "        dot.render(save_path)\n",
    "        print(f\"Computational graph saved as {save_path}.png\")\n",
    "        \n",
    "        # Also print parameter connections\n",
    "        print(\"\\nParameter connections in graph:\")\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.grad_fn is not None:\n",
    "                print(f\"{name}: Connected (grad_fn = {param.grad_fn})\")\n",
    "            else:\n",
    "                print(f\"{name}: NOT connected (no grad_fn)\")\n",
    "    else:\n",
    "        print(\"torchviz not available for visualization\")\n",
    "\n",
    "def trace_computation_graph(tensor, depth=0, max_depth=5):\n",
    "    \"\"\"Manually trace the computational graph\"\"\"\n",
    "    if depth > max_depth:\n",
    "        return\n",
    "    \n",
    "    indent = \"  \" * depth\n",
    "    print(f\"{indent}Tensor: {tensor.shape if hasattr(tensor, 'shape') else 'scalar'}\")\n",
    "    print(f\"{indent}grad_fn: {tensor.grad_fn}\")\n",
    "    print(f\"{indent}requires_grad: {tensor.requires_grad}\")\n",
    "    \n",
    "    if hasattr(tensor, 'grad_fn') and tensor.grad_fn is not None:\n",
    "        if hasattr(tensor.grad_fn, 'next_functions'):\n",
    "            for i, (next_fn, _) in enumerate(tensor.grad_fn.next_functions):\n",
    "                if next_fn is not None:\n",
    "                    print(f\"{indent}  -> next_function[{i}]: {next_fn}\")\n",
    "                    if hasattr(next_fn, 'variable') and next_fn.variable is not None:\n",
    "                        print(f\"{indent}     variable shape: {next_fn.variable.shape}\")\n",
    "                        trace_computation_graph(next_fn.variable, depth+1, max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31b554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_parameter_usage(model, loss):\n",
    "    \"\"\"Debug which parameters are actually used in computation\"\"\"\n",
    "    \n",
    "    print(\"=== DEBUGGING PARAMETER USAGE ===\")\n",
    "    \n",
    "    # Check if loss requires grad\n",
    "    print(f\"Loss requires_grad: {loss.requires_grad}\")\n",
    "    print(f\"Loss grad_fn: {loss.grad_fn}\")\n",
    "    \n",
    "    # Check each parameter\n",
    "    print(\"\\nParameter status:\")\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"  requires_grad: {param.requires_grad}\")\n",
    "        print(f\"  grad_fn: {param.grad_fn}\")\n",
    "        print(f\"  is_leaf: {param.is_leaf}\")\n",
    "        print(f\"  value: {param.data}\")\n",
    "        \n",
    "        # Check if parameter is used in computation\n",
    "        if param.grad_fn is not None:\n",
    "            print(f\"  ✓ Connected to computation graph\")\n",
    "        else:\n",
    "            print(f\"  ✗ NOT connected to computation graph\")\n",
    "    \n",
    "    print(\"\\n=== TRACING LOSS COMPUTATION ===\")\n",
    "    trace_computation_graph(loss)\n",
    "\n",
    "def check_sde_computation_flow(model, times, z0s):\n",
    "    \"\"\"Check if SDE computation connects to parameters\"\"\"\n",
    "    \n",
    "    print(\"=== CHECKING SDE COMPUTATION FLOW ===\")\n",
    "    \n",
    "    # Check if z0s connects to qz0_mean and qz0_logvar\n",
    "    print(f\"z0s requires_grad: {z0s.requires_grad}\")\n",
    "    print(f\"z0s grad_fn: {z0s.grad_fn}\")\n",
    "    \n",
    "    # Manually check if qz0_mean is used in z0s computation\n",
    "    print(f\"\\nqz0_mean in z0s computation: {model.qz0_mean.grad_fn is not None}\")\n",
    "    print(f\"qz0_logvar in z0s computation: {model.qz0_logvar.grad_fn is not None}\")\n",
    "    \n",
    "    # Check the SDE integration\n",
    "    print(f\"\\nChecking torchsde.sdeint connection...\")\n",
    "    # The issue might be here - torchsde.sdeint might break the gradient flow"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
